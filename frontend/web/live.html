<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Realitic ‚Äî Live Detection</title>
  <link rel="icon" id="pageFavicon" type="image/png" href="">
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
      background: #0F172A;
      color: #fff;
      min-height: 100vh;
    }

    .header {
      display: flex;
      align-items: center;
      justify-content: space-between;
      padding: 16px 24px;
      background: #1E293B;
      border-bottom: 1px solid rgba(255, 255, 255, 0.06);
    }

    .header h1 {
      font-size: 20px;
      font-weight: 700;
      display: flex;
      align-items: center;
      gap: 10px;
    }

    .header h1 .icon {
      width: 32px;
      height: 32px;
      background: rgba(129, 140, 248, 0.2);
      border-radius: 8px;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 18px;
    }

    .controls {
      display: flex;
      gap: 12px;
      align-items: center;
    }

    .btn {
      padding: 10px 20px;
      border: none;
      border-radius: 10px;
      font-size: 14px;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.2s;
      display: flex;
      align-items: center;
      gap: 8px;
    }

    .btn-start {
      background: linear-gradient(135deg, #22C55E, #16A34A);
      color: white;
    }

    .btn-start:hover {
      transform: translateY(-1px);
      box-shadow: 0 4px 12px rgba(34, 197, 94, 0.3);
    }

    .btn-stop {
      background: linear-gradient(135deg, #EF4444, #DC2626);
      color: white;
    }

    .btn-stop:hover {
      transform: translateY(-1px);
      box-shadow: 0 4px 12px rgba(239, 68, 68, 0.3);
    }

    .btn:disabled {
      opacity: 0.4;
      cursor: not-allowed;
      transform: none !important;
      box-shadow: none !important;
    }

    .btn-pip {
      background: rgba(129, 140, 248, 0.12);
      border: 1px solid rgba(129, 140, 248, 0.28);
      color: #818CF8;
    }

    .btn-pip:hover {
      background: rgba(129, 140, 248, 0.22);
      transform: translateY(-1px);
    }

    .btn-pip.active {
      background: rgba(129, 140, 248, 0.28);
      border-color: rgba(129, 140, 248, 0.55);
      box-shadow: 0 0 12px rgba(129, 140, 248, 0.2);
    }

    .main {
      display: flex;
      gap: 20px;
      padding: 20px;
      height: calc(100vh - 68px);
    }

    .video-panel {
      flex: 1;
      position: relative;
      background: #1E293B;
      border-radius: 16px;
      overflow: hidden;
      border: 1px solid rgba(255, 255, 255, 0.06);
    }

    #screenVideo {
      width: 100%;
      height: 100%;
      object-fit: contain;
      background: #000;
    }

    /* Face-box overlay ‚Äî sits directly on top of the video */
    #faceOverlay {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
      /* clicks pass through to video */
    }

    .placeholder {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      text-align: center;
      color: rgba(255, 255, 255, 0.3);
    }

    .placeholder .big-icon {
      font-size: 64px;
      margin-bottom: 16px;
    }

    .placeholder p {
      font-size: 16px;
    }

    /* Floating verdict overlay */
    .verdict-overlay {
      position: absolute;
      top: 16px;
      right: 16px;
      padding: 14px 22px;
      border-radius: 14px;
      display: none;
      flex-direction: column;
      gap: 4px;
      backdrop-filter: blur(16px);
      z-index: 10;
      transition: all 0.3s ease;
      max-width: 340px;
    }

    .verdict-overlay .vo-main {
      font-size: 20px;
      font-weight: 800;
      letter-spacing: 2px;
    }

    .verdict-overlay .vo-band {
      font-size: 12px;
      font-weight: 600;
      opacity: 0.8;
    }

    .verdict-overlay .vo-why {
      font-size: 11px;
      opacity: 0.65;
      margin-top: 2px;
    }

    .verdict-overlay.real {
      display: flex;
      background: rgba(34, 197, 94, 0.2);
      border: 1px solid rgba(34, 197, 94, 0.4);
      color: #22C55E;
    }

    .verdict-overlay.fake {
      display: flex;
      background: rgba(239, 68, 68, 0.2);
      border: 1px solid rgba(239, 68, 68, 0.4);
      color: #EF4444;
      animation: pulse-red 1.5s infinite;
    }

    .verdict-overlay.uncertain {
      display: flex;
      background: rgba(245, 158, 11, 0.2);
      border: 1px solid rgba(245, 158, 11, 0.4);
      color: #F59E0B;
    }

    .verdict-overlay.analyzing {
      display: flex;
      background: rgba(129, 140, 248, 0.2);
      border: 1px solid rgba(129, 140, 248, 0.4);
      color: #818CF8;
    }

    @keyframes pulse-red {

      0%,
      100% {
        box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.3);
      }

      50% {
        box-shadow: 0 0 20px 4px rgba(239, 68, 68, 0.2);
      }
    }

    /* Side panel */
    .side-panel {
      width: 370px;
      display: flex;
      flex-direction: column;
      gap: 14px;
      overflow-y: auto;
    }

    .card {
      background: #1E293B;
      border-radius: 14px;
      padding: 20px;
      border: 1px solid rgba(255, 255, 255, 0.06);
    }

    .card h3 {
      font-size: 13px;
      color: rgba(255, 255, 255, 0.45);
      text-transform: uppercase;
      letter-spacing: 1px;
      margin-bottom: 10px;
      display: flex;
      align-items: center;
      gap: 8px;
    }

    /* Verdict card */
    .vc-icon {
      font-size: 36px;
      line-height: 1;
    }

    .vc-verdict {
      font-size: 28px;
      font-weight: 800;
      letter-spacing: 3px;
    }

    .vc-band {
      font-size: 13px;
      font-weight: 600;
      opacity: 0.75;
      margin-top: 2px;
    }

    .vc-why {
      font-size: 13px;
      color: rgba(255, 255, 255, 0.6);
      margin-top: 10px;
      line-height: 1.4;
    }

    .vc-steps {
      list-style: none;
      margin-top: 10px;
      padding: 0;
    }

    .vc-steps li {
      font-size: 12px;
      color: rgba(255, 255, 255, 0.55);
      padding: 4px 0;
      padding-left: 18px;
      position: relative;
      line-height: 1.5;
    }

    .vc-steps li::before {
      content: '';
      position: absolute;
      left: 0;
      top: 9px;
      width: 8px;
      height: 8px;
      border-radius: 50%;
      border: 1.5px solid rgba(255, 255, 255, 0.25);
    }

    /* Audio card */
    .audio-indicator {
      display: flex;
      align-items: center;
      gap: 8px;
      padding: 8px 12px;
      border-radius: 8px;
      background: rgba(129, 140, 248, 0.1);
      font-size: 13px;
      color: #818CF8;
    }

    .audio-bars {
      display: flex;
      gap: 2px;
      align-items: flex-end;
      height: 16px;
    }

    .audio-bars span {
      width: 3px;
      background: #818CF8;
      border-radius: 2px;
      animation: audio-bar 0.8s ease-in-out infinite;
    }

    .audio-bars span:nth-child(1) {
      height: 6px;
      animation-delay: 0s;
    }

    .audio-bars span:nth-child(2) {
      height: 12px;
      animation-delay: 0.15s;
    }

    .audio-bars span:nth-child(3) {
      height: 8px;
      animation-delay: 0.3s;
    }

    .audio-bars span:nth-child(4) {
      height: 14px;
      animation-delay: 0.45s;
    }

    .audio-bars span:nth-child(5) {
      height: 10px;
      animation-delay: 0.6s;
    }

    @keyframes audio-bar {

      0%,
      100% {
        transform: scaleY(1);
      }

      50% {
        transform: scaleY(0.4);
      }
    }

    #audioCanvas {
      width: 100%;
      height: 32px;
      border-radius: 8px;
      background: rgba(0, 0, 0, 0.2);
      margin-top: 8px;
    }

    /* Details toggle */
    .details-toggle {
      display: flex;
      align-items: center;
      justify-content: space-between;
      cursor: pointer;
      user-select: none;
    }

    .details-toggle::after {
      content: '\25B6';
      font-size: 10px;
      color: rgba(255, 255, 255, 0.3);
      transition: transform 0.2s;
    }

    .details-toggle.open::after {
      transform: rotate(90deg);
    }

    .details-body {
      display: none;
      margin-top: 10px;
    }

    .details-body.open {
      display: block;
    }

    .detail-row {
      display: flex;
      justify-content: space-between;
      padding: 4px 0;
      font-size: 12px;
    }

    .detail-row .dl {
      color: rgba(255, 255, 255, 0.4);
    }

    .detail-row .dv {
      font-weight: 600;
      color: rgba(255, 255, 255, 0.7);
    }

    /* Log */
    .log-entry {
      padding: 6px 10px;
      border-radius: 8px;
      margin-bottom: 4px;
      font-size: 11px;
      display: flex;
      align-items: center;
      gap: 6px;
    }

    .log-entry.real {
      background: rgba(34, 197, 94, 0.08);
      color: #22C55E;
    }

    .log-entry.fake {
      background: rgba(239, 68, 68, 0.08);
      color: #EF4444;
    }

    .log-entry.uncertain {
      background: rgba(245, 158, 11, 0.08);
      color: #F59E0B;
    }

    .log-entry.analyzing {
      background: rgba(129, 140, 248, 0.08);
      color: #818CF8;
    }

    .log-container {
      max-height: 260px;
      overflow-y: auto;
    }

    .fraud-block {
      margin-top: 12px;
      padding-top: 12px;
      border-top: 1px solid rgba(255, 255, 255, 0.08);
      font-size: 12px;
      color: rgba(255, 255, 255, 0.75);
    }

    .fraud-block .fraud-title {
      font-weight: 700;
      font-size: 11px;
      text-transform: uppercase;
      letter-spacing: 0.5px;
      color: rgba(255, 255, 255, 0.9);
      margin-bottom: 6px;
    }

    .fraud-block .fraud-risk {
      font-weight: 700;
    }

    .fraud-block .fraud-risk.high {
      color: #F87171;
    }

    .fraud-block .fraud-risk.medium {
      color: #FBBF24;
    }

    .fraud-block .fraud-risk.low {
      color: #4ADE80;
    }

    .fraud-block .fraud-evidence {
      margin-top: 6px;
      padding-left: 12px;
      list-style: disc;
      color: rgba(255, 255, 255, 0.7);
    }

    .interval-select {
      background: #334155;
      color: white;
      border: 1px solid rgba(255, 255, 255, 0.1);
      border-radius: 8px;
      padding: 8px 12px;
      font-size: 13px;
    }
  </style>
</head>

<body>
  <!-- Header -->
  <div class="header">
    <h1>
      <span class="icon">üõ°Ô∏è</span>
      Realitic ‚Äî Live Detection
    </h1>
    <div class="controls">
      <label style="font-size:13px; color:rgba(255,255,255,0.5);">
        Scan every:
        <select id="intervalSelect" class="interval-select">
          <option value="2000">2s</option>
          <option value="3000" selected>3s</option>
          <option value="5000">5s</option>
          <option value="10000">10s</option>
        </select>
      </label>
      <button id="btnPip" class="btn btn-pip" onclick="toggleWidget()"
        title="Float results in a mini window ‚Äî stays visible on other tabs">
        ‚ßâ Pop Out
      </button>
      <button id="btnStart" class="btn btn-start" onclick="startCapture()">
        ‚ñ∂ Start Capture
      </button>
      <button id="btnStop" class="btn btn-stop" onclick="stopCapture()" disabled>
        ‚ñ† Stop
      </button>
    </div>
  </div>

  <!-- Main layout -->
  <div class="main">
    <!-- Video panel -->
    <div class="video-panel">
      <video id="screenVideo" autoplay muted></video>
      <canvas id="faceOverlay"></canvas>
      <div id="placeholder" class="placeholder">
        <div class="big-icon">üñ•Ô∏è</div>
        <p>Click "Start Capture" to share your screen</p>
        <p style="font-size:13px; margin-top:8px; opacity:0.5">
          Select a window, tab, or entire screen
        </p>
      </div>
      <div id="verdictOverlay" class="verdict-overlay"></div>
    </div>

    <!-- Side panel -->
    <div class="side-panel">

      <!-- Card 1: Video Verdict -->
      <div class="card" id="videoVerdictCard">
        <h3>üñ• Video Analysis</h3>
        <div id="videoVerdictArea" style="text-align:center; padding:10px 0">
          <div style="font-size:13px; color:rgba(255,255,255,0.35)">
            Click "Start Capture" to begin
          </div>
        </div>
      </div>

      <!-- Card 2: Audio Verdict -->
      <div class="card" id="audioVerdictCard">
        <h3>üéô Audio Analysis</h3>
        <div id="audioStatus">
          <div style="font-size:13px; color:rgba(255,255,255,0.35)">
            Audio capture starts with screen share
          </div>
        </div>
        <canvas id="audioCanvas"></canvas>
      </div>

      <!-- Card 3: Technical Details (collapsed) -->
      <div class="card">
        <h3 class="details-toggle" id="detailsToggle" onclick="toggleDetails()">
          üî¨ Technical Details
        </h3>
        <div class="details-body" id="detailsBody">
          <div class="detail-row"><span class="dl">State</span><span class="dv" id="statState">Idle</span></div>
          <div class="detail-row"><span class="dl">Frames analyzed</span><span class="dv" id="statFrames">0</span></div>
          <div class="detail-row"><span class="dl">Fake detections</span><span class="dv" id="statFakes"
              style="color:#EF4444">0</span></div>
          <div class="detail-row"><span class="dl">Real detections</span><span class="dv" id="statReals"
              style="color:#22C55E">0</span></div>
          <div class="detail-row"><span class="dl">Avg confidence</span><span class="dv" id="statConfidence">-</span>
          </div>
          <div id="detailsExtra" style="margin-top:6px; font-size:11px; color:rgba(255,255,255,0.35)"></div>
        </div>
      </div>

      <!-- Card 4: Detection Log -->
      <div class="card" style="flex:1;">
        <h3>üìã Detection Log</h3>
        <div id="logContainer" class="log-container">
          <div class="log-entry analyzing">Waiting to start...</div>
        </div>
      </div>
    </div>
  </div>

  <!-- Hidden canvas for frame extraction -->
  <canvas id="frameCanvas" style="display:none;"></canvas>

  <script>
    // ---- Face overlay canvas ----
    const faceOverlay = document.getElementById('faceOverlay');
    const faceCtx = faceOverlay.getContext('2d');

    // Colour per verdict
    const VERDICT_COLOR = {
      real: '#22C55E',
      fake: '#EF4444',
      uncertain: '#F59E0B',
    };

    function drawFaceBox(bbox, prediction) {
      // Sync canvas size to its CSS display size
      faceOverlay.width = faceOverlay.clientWidth;
      faceOverlay.height = faceOverlay.clientHeight;
      faceCtx.clearRect(0, 0, faceOverlay.width, faceOverlay.height);

      if (!bbox) return;

      // The video uses object-fit:contain, so we need the actual rendered rect
      const videoEl = document.getElementById('screenVideo');
      const vw = videoEl.videoWidth;
      const vh = videoEl.videoHeight;
      const cw = faceOverlay.clientWidth;
      const ch = faceOverlay.clientHeight;

      if (!vw || !vh) return;

      // Letterbox / pillarbox offsets
      const scale = Math.min(cw / vw, ch / vh);
      const offsetX = (cw - vw * scale) / 2;
      const offsetY = (ch - vh * scale) / 2;

      // Convert normalised bbox ‚Üí canvas pixels
      const rx = offsetX + bbox.x * vw * scale;
      const ry = offsetY + bbox.y * vh * scale;
      const rw = bbox.w * vw * scale;
      const rh = bbox.h * vh * scale;

      const color = VERDICT_COLOR[prediction.toLowerCase()] || '#818CF8';

      // Outer glow
      faceCtx.shadowColor = color;
      faceCtx.shadowBlur = 12;
      faceCtx.strokeStyle = color;
      faceCtx.lineWidth = 2.5;
      faceCtx.strokeRect(rx, ry, rw, rh);
      faceCtx.shadowBlur = 0;

      // Corner accents (L-shaped brackets)
      const cs = Math.min(rw, rh) * 0.18;  // corner segment length
      faceCtx.lineWidth = 3.5;
      faceCtx.strokeStyle = color;

      const corners = [
        [rx, ry, cs, 0, 0, cs],   // top-left
        [rx + rw, ry, -cs, 0, 0, cs],   // top-right
        [rx, ry + rh, cs, 0, 0, -cs],   // bottom-left
        [rx + rw, ry + rh, -cs, 0, 0, -cs],   // bottom-right
      ];
      for (const [x, y, dx1, dy1, dx2, dy2] of corners) {
        faceCtx.beginPath();
        faceCtx.moveTo(x + dx1, y + dy1);
        faceCtx.lineTo(x, y);
        faceCtx.lineTo(x + dx2, y + dy2);
        faceCtx.stroke();
      }

      // Label pill above the box
      const label = prediction.toUpperCase();
      const font = 'bold 13px Inter, -apple-system, sans-serif';
      faceCtx.font = font;
      const tw = faceCtx.measureText(label).width;
      const ph = 22;
      const pw = tw + 18;
      const px = rx + (rw - pw) / 2;
      const py = ry - ph - 6;

      faceCtx.fillStyle = color + 'CC';   // semi-transparent fill
      roundRect(faceCtx, px, py, pw, ph, 6);
      faceCtx.fill();

      faceCtx.fillStyle = '#fff';
      faceCtx.font = font;
      faceCtx.textAlign = 'center';
      faceCtx.fillText(label, px + pw / 2, py + 15);
      faceCtx.textAlign = 'left';
    }

    function roundRect(ctx, x, y, w, h, r) {
      ctx.beginPath();
      ctx.moveTo(x + r, y);
      ctx.lineTo(x + w - r, y);
      ctx.arcTo(x + w, y, x + w, y + r, r);
      ctx.lineTo(x + w, y + h - r);
      ctx.arcTo(x + w, y + h, x + w - r, y + h, r);
      ctx.lineTo(x + r, y + h);
      ctx.arcTo(x, y + h, x, y + h - r, r);
      ctx.lineTo(x, y + r);
      ctx.arcTo(x, y, x + r, y, r);
      ctx.closePath();
    }

    function clearFaceBox() {
      faceOverlay.width = faceOverlay.clientWidth;
      faceOverlay.height = faceOverlay.clientHeight;
      faceCtx.clearRect(0, 0, faceOverlay.width, faceOverlay.height);
    }

    // ---- State ----
    let stream = null;
    let audioStream = null;
    let mediaRecorder = null;
    let audioChunks = [];
    let audioAnalysisBuffer = [];   // rolling window for live audio detection
    let audioHeaderChunk = null;    // first chunk contains the WebM/EBML header ‚Äî must prefix every blob
    const AUDIO_BUFFER_MAX = 5;     // ~5 s at 1 s/chunk ‚Äî enough for the models
    let isAnalyzingAudio = false;
    let lastFraudAnalysisTime = 0;
    let scanInterval = null;
    let frameCount = 0;
    let fakeCount = 0;
    let realCount = 0;
    let totalConfidence = 0;
    let isAnalyzing = false;
    let audioContext = null;
    let analyserNode = null;
    let animFrameId = null;
    let audioChunkWatchdog = null;
    let lastFraudHtml = null;
    let lastFraudUpdateTime = null;
    const FRAUD_DISPLAY_MS = 10000;
    let audioAnalyzedOnce = false;

    const API_BASE = window.location.origin; // same server

    // ---- Elements ----
    const video = document.getElementById('screenVideo');
    const placeholder = document.getElementById('placeholder');
    const verdictOverlay = document.getElementById('verdictOverlay');
    const logContainer = document.getElementById('logContainer');
    const canvas = document.getElementById('frameCanvas');
    const ctx = canvas.getContext('2d');
    const audioCanvas = document.getElementById('audioCanvas');
    const audioCtx2d = audioCanvas.getContext('2d');

    // ---- Start capture ----
    async function startCapture() {
      try {
        // Request screen + audio; systemAudio: 'include' so "Share system audio" is offered for screen/window
        try {
          stream = await navigator.mediaDevices.getDisplayMedia({
            video: { cursor: 'always' },
            audio: {
              suppressLocalAudioPlayback: true,
            },
            systemAudio: 'include',
          });
        } catch (optErr) {
          if (optErr.name === 'TypeError' || optErr.name === 'OverconstrainedError') {
            stream = await navigator.mediaDevices.getDisplayMedia({
              video: { cursor: 'always' },
              audio: true,
            });
          } else {
            throw optErr;
          }
        }

        video.srcObject = stream;
        placeholder.style.display = 'none';

        document.getElementById('btnStart').disabled = true;
        document.getElementById('btnStop').disabled = false;
        document.getElementById('statState').textContent = 'üü¢ Capturing';

        // Audio: use stream audio when present (tab or system audio from screen/window)
        let audioSourceStream = null;
        const screenAudioTracks = stream.getAudioTracks();
        const surface = stream.getVideoTracks()[0]?.getSettings?.().displaySurface || '';
        const isBrowserTabCapture = surface === 'browser';

        if (screenAudioTracks.length > 0) {
          audioSourceStream = stream;
          document.getElementById('audioStatus').innerHTML = `
            <div class="audio-indicator">
              <div class="audio-bars">
                <span></span><span></span><span></span><span></span><span></span>
              </div>
              ${isBrowserTabCapture ? 'Recording tab audio...' : 'Recording system/window audio...'}
            </div>
          `;
        } else {
          // No audio from screen share ‚Äî request microphone
          try {
            const micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
            audioSourceStream = micStream;
            // Keep a reference so we can stop mic tracks later
            audioStream = micStream;
            document.getElementById('audioStatus').innerHTML = `
              <div class="audio-indicator">
                <div class="audio-bars">
                  <span></span><span></span><span></span><span></span><span></span>
                </div>
                üé§ Recording via microphone... ${!isBrowserTabCapture && screenAudioTracks.length > 0 ? '(screen/window audio not supported reliably)' : ''}
              </div>
            `;
          } catch (micErr) {
            console.warn('Microphone access denied:', micErr);
            document.getElementById('audioStatus').innerHTML = `
              <div style="font-size:13px; color:#F59E0B">
                ‚ö†Ô∏è No audio source
              </div>
            `;
          }
        }

        if (audioSourceStream) {
          startAudioVisualization(audioSourceStream);
          startAudioRecording(audioSourceStream);
        }

        // Start scanning frames + audio in parallel
        const interval = parseInt(document.getElementById('intervalSelect').value);
        scanInterval = setInterval(() => {
          analyzeFrame();
          analyzeAudio();
        }, interval);

        // Handle stream ending (user clicks "Stop sharing")
        stream.getVideoTracks()[0].onended = () => stopCapture();

        addLog('analyzing', 'üü¢ Capture started ‚Äî scanning every ' +
          (interval / 1000) + 's');
      } catch (err) {
        console.error('Screen capture failed:', err);
        addLog('uncertain', '‚ùå Screen capture cancelled or denied');
      }
    }

    // ---- Stop capture ----
    function stopCapture() {
      if (stream) {
        stream.getTracks().forEach(t => t.stop());
        stream = null;
      }
      if (audioStream) {
        audioStream.getTracks().forEach(t => t.stop());
        audioStream = null;
      }

      if (scanInterval) {
        clearInterval(scanInterval);
        scanInterval = null;
      }

      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
      }
      if (audioChunkWatchdog) {
        clearTimeout(audioChunkWatchdog);
        audioChunkWatchdog = null;
      }
      lastFraudHtml = null;
      lastFraudUpdateTime = null;
      audioAnalyzedOnce = false;

      if (audioContext) {
        audioContext.close();
        audioContext = null;
      }

      if (animFrameId) {
        cancelAnimationFrame(animFrameId);
        animFrameId = null;
      }

      video.srcObject = null;
      placeholder.style.display = '';
      verdictOverlay.className = 'verdict-overlay';
      verdictOverlay.style.display = 'none';
      clearFaceBox();

      document.getElementById('btnStart').disabled = false;
      document.getElementById('btnStop').disabled = true;
      document.getElementById('statState').textContent = '‚èπ Stopped';

      audioAnalysisBuffer = [];
      audioHeaderChunk = null;
      isAnalyzingAudio = false;
      addLog('analyzing', '‚èπ Capture stopped');
      resetTabTitle();

      // If we have audio, offer download
      if (audioChunks.length > 0) {
        const blob = new Blob(audioChunks, { type: 'audio/webm' });
        const url = URL.createObjectURL(blob);
        addLog('analyzing',
          `üéôÔ∏è Audio recorded ‚Äî <a href="${url}" download="captured_audio.webm" style="color:#818CF8">Download</a>`
        );
        audioChunks = [];
      }
    }

    // ---- Analyze a single frame ----
    async function analyzeFrame() {
      if (isAnalyzing || !stream) return;
      isAnalyzing = true;

      try {
        // Extract frame from video
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0);

        // Convert to blob
        const blob = await new Promise(resolve =>
          canvas.toBlob(resolve, 'image/jpeg', 0.85)
        );

        if (!blob) {
          isAnalyzing = false;
          return;
        }

        // Show analyzing state
        verdictOverlay.className = 'verdict-overlay analyzing';
        verdictOverlay.textContent = 'üîç Analyzing...';

        // Send to API
        const formData = new FormData();
        formData.append('file', blob, 'frame.jpg');

        const response = await fetch(`${API_BASE}/predict`, {
          method: 'POST',
          body: formData
        });

        if (!response.ok) {
          const err = await response.json();
          throw new Error(err.detail || 'API error');
        }

        const result = await response.json();
        frameCount++;

        const v = result.verdict || 'UNCERTAIN';
        const vl = v.toLowerCase();
        const pFake = result.final_p_fake ?? 0.5;
        const band = result.confidence_band || '';
        const bandLabel = BAND_LABELS[band] || '';
        const why = result.advice ? result.advice.why : '';

        // ‚îÄ‚îÄ Verdict overlay on video (user-friendly) ‚îÄ‚îÄ
        verdictOverlay.className = `verdict-overlay ${vl}`;
        verdictOverlay.innerHTML = `
          <div class="vo-main">${getEmoji(vl)} ${v}</div>
          <div class="vo-band">${bandLabel}</div>
          ${why ? `<div class="vo-why">${why}</div>` : ''}
        `;

        // ‚îÄ‚îÄ Face bounding box ‚îÄ‚îÄ
        const bbox = result.signals ? result.signals.face_bbox : null;
        const faceFound = result.signals ? result.signals.face_found : false;
        drawFaceBox(bbox, v);

        // ‚îÄ‚îÄ Side panel: video verdict card ‚îÄ‚îÄ
        renderVerdictCard(document.getElementById('videoVerdictArea'), result, 'video');

        // ‚îÄ‚îÄ Stats (in collapsed details) ‚îÄ‚îÄ
        if (vl === 'fake') fakeCount++;
        else if (vl === 'real') realCount++;
        totalConfidence += Math.max(pFake, 1 - pFake) * 100;

        document.getElementById('statFrames').textContent = frameCount;
        document.getElementById('statFakes').textContent = fakeCount;
        document.getElementById('statReals').textContent = realCount;
        document.getElementById('statConfidence').textContent =
          (totalConfidence / frameCount).toFixed(1) + '%';

        // Technical details (models, timing, etc.)
        const detExtra = document.getElementById('detailsExtra');
        if (detExtra && result.models) {
          detExtra.innerHTML = result.models.map(m =>
            `<div class="detail-row"><span class="dl">${m.name}</span><span class="dv">${(m.p_fake * 100).toFixed(1)}%${m.used ? '' : ' (unused)'}</span></div>`
          ).join('') +
            (result.timing_ms ? `<div class="detail-row"><span class="dl">Timing</span><span class="dv">${result.timing_ms.total}ms</span></div>` : '');
        }

        // ‚îÄ‚îÄ Simplified log entry ‚îÄ‚îÄ
        const time = new Date().toLocaleTimeString();
        addLog(vl, `${getEmoji(vl)} ${time} ‚Äî ${v} &middot; ${bandLabel}`);

        // ‚îÄ‚îÄ Always-visible feedback (tab title, favicon, floating widget) ‚îÄ‚îÄ
        updateTabTitle(v, bandLabel);
        updateFavicon(v);
        const thumbDataUrl = createFaceThumbnail(bbox, v);
        updateWidget(v, pFake, band, time, thumbDataUrl, why);

      } catch (err) {
        console.error('Analysis error:', err);
        addLog('uncertain', `‚ö†Ô∏è Error: ${err.message}`);
      }

      isAnalyzing = false;
    }

    // ---- Audio recording ----
    async function startAudioRecording(mediaStream) {
      try {
        const audioTracks = mediaStream.getAudioTracks();
        if (audioTracks.length === 0) {
          console.warn('startAudioRecording: no audio tracks in stream');
          _showAudioError('No audio tracks found in stream');
          return;
        }

        // Route through AudioContext to produce a fresh MediaStream.
        // Chrome blocks MediaRecorder on raw getDisplayMedia audio
        // tracks inside iframes; piping via AudioContext bypasses this.
        const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
        if (audioCtx.state === 'suspended') await audioCtx.resume();
        const source = audioCtx.createMediaStreamSource(new MediaStream(audioTracks));
        const dest = audioCtx.createMediaStreamDestination();
        source.connect(dest);
        const recordableStream = dest.stream;

        const mimeTypes = [
          'audio/webm;codecs=opus',
          'audio/webm',
          'audio/ogg;codecs=opus',
          '',
        ];
        let chosenMime = '';
        for (const mt of mimeTypes) {
          if (!mt || MediaRecorder.isTypeSupported(mt)) { chosenMime = mt; break; }
        }

        const opts = chosenMime ? { mimeType: chosenMime } : undefined;
        mediaRecorder = new MediaRecorder(recordableStream, opts);
        audioChunks = [];
        audioAnalysisBuffer = [];
        audioHeaderChunk = null;

        mediaRecorder.ondataavailable = (e) => {
          if (e.data.size > 0) {
            audioChunks.push(e.data);
            if (!audioHeaderChunk) {
              audioHeaderChunk = e.data;
            }
            audioAnalysisBuffer.push(e.data);
            if (audioAnalysisBuffer.length > AUDIO_BUFFER_MAX) {
              audioAnalysisBuffer.shift();
            }
          }
        };

        mediaRecorder.onerror = (e) => {
          console.error('MediaRecorder error:', e);
          _showAudioError('Audio recorder error');
        };

        mediaRecorder.start(1000);
        console.log('MediaRecorder started with mimeType:', mediaRecorder.mimeType);

        // If recorder starts but emits no usable chunks, tab audio is likely unavailable.
        // Common on macOS when sharing non-browser apps; fallback to mic if possible.
        if (audioChunkWatchdog) clearTimeout(audioChunkWatchdog);
        audioChunkWatchdog = setTimeout(() => {
          if (audioAnalysisBuffer.length === 0) {
            try {
              if (mediaRecorder && mediaRecorder.state !== 'inactive') mediaRecorder.stop();
            } catch (_) { }
            trySwitchToMicAudio('No tab audio detected');
          }
        }, 4500);
      } catch (err) {
        console.error('Audio recording failed:', err);
        const inIframe = window.self !== window.top;
        const hint = inIframe
          ? ' ‚Äî <a href="' + window.location.origin + '/live" target="_blank" style="color:#818CF8;text-decoration:underline">Open in new tab</a> for full audio support'
          : '';
        _showAudioError('Audio recording failed' + hint);
      }
    }

    async function trySwitchToMicAudio(reason) {
      try {
        const micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        audioStream = micStream;
        startAudioVisualization(micStream);
        startAudioRecording(micStream);
        document.getElementById('audioStatus').innerHTML =
          '<div class="audio-indicator"><div class="audio-bars">' +
          '<span></span><span></span><span></span><span></span><span></span>' +
          '</div>üé§ Switched to microphone (' + reason + ')</div>';
      } catch (micErr) {
        _showAudioError(
          reason + '. On macOS, tab capture records browser-tab audio only; for desktop apps, allow microphone.'
        );
      }
    }

    // Show a transient error in the audio side-panel card
    function _showAudioError(msg) {
      const el = document.getElementById('audioStatus');
      if (el) el.innerHTML = `<div style="font-size:12px;color:#F59E0B">‚ö†Ô∏è ${msg}</div>`;
    }

    // ---- Real-time audio deepfake analysis ----
    async function analyzeAudio() {
      if (audioAnalyzedOnce) return;
      if (isAnalyzingAudio || audioAnalysisBuffer.length < 3 || !stream) return;
      isAnalyzingAudio = true;

      try {
        // Prepend the header chunk so the blob is always a valid WebM file
        const parts = audioHeaderChunk && audioAnalysisBuffer[0] !== audioHeaderChunk
          ? [audioHeaderChunk, ...audioAnalysisBuffer]
          : [...audioAnalysisBuffer];
        const blob = new Blob(parts, { type: 'audio/webm' });
        if (blob.size < 2000) { isAnalyzingAudio = false; return; }

        const fd = new FormData();
        fd.append('file', blob, 'live_audio.webm');

        const resp = await fetch(`${API_BASE}/predict-audio`, { method: 'POST', body: fd });
        if (!resp.ok) {
          const errBody = await resp.json().catch(() => ({}));
          const detail = errBody.detail || `HTTP ${resp.status}`;
          console.warn('Audio API error:', detail);
          _showAudioError(detail);
          isAnalyzingAudio = false;
          return;
        }

        const result = await resp.json();

        let fraudResult = null;
        try {
          const now = Date.now();
          if (now - lastFraudAnalysisTime > 15000) {
            lastFraudAnalysisTime = now;
            const fdFraud = new FormData();
            fdFraud.append('file', blob, 'live_audio.webm');
            const fraudResp = await fetch(`${API_BASE}/analyze-fraud`, { method: 'POST', body: fdFraud });
            if (fraudResp.ok) fraudResult = await fraudResp.json();
          }
        } catch (e) {
          console.warn('Fraud analysis failed:', e);
          lastFraudAnalysisTime = 0;
        }

        // ‚îÄ‚îÄ Side panel update ‚îÄ‚îÄ
        updateAudioDisplay(result, fraudResult);

        // ‚îÄ‚îÄ Floating widget ‚îÄ‚îÄ
        updateWidgetAudio(result);

        // ‚îÄ‚îÄ Log entry ‚îÄ‚îÄ
        const v = result.verdict || 'UNCERTAIN';
        const vl2 = v.toLowerCase();
        const bandLabel2 = BAND_LABELS[result.confidence_band] || '';
        const time = new Date().toLocaleTimeString();
        addLog(vl2, `üéô ${time} ‚Äî Audio ${v} &middot; ${bandLabel2}`);

        audioAnalyzedOnce = true;
      } catch (err) {
        console.error('Audio analysis error:', err);
        _showAudioError(err.message || 'Unknown error');
      }

      isAnalyzingAudio = false;
    }

    // Update the audio card in the side panel with live result
    function updateAudioDisplay(result, fraudResult) {
      const statusEl = document.getElementById('audioStatus');
      if (!statusEl) return;
      renderVerdictCard(statusEl, result, 'audio');
      const now = Date.now();
      const shouldUpdateFraud = fraudResult && (!lastFraudUpdateTime || (now - lastFraudUpdateTime >= FRAUD_DISPLAY_MS));
      if (shouldUpdateFraud) {
        lastFraudHtml = getFraudBlockHtml(fraudResult);
        lastFraudUpdateTime = now;
      }
      if (lastFraudHtml) {
        const div = document.createElement('div');
        div.className = 'fraud-block';
        div.innerHTML = lastFraudHtml;
        statusEl.appendChild(div);
      }
    }

    function getFraudBlockHtml(fraud) {
      const esc = (s) => {
        if (s == null || s === '') return '';
        s = String(s);
        return s.replace(/&/g, '&amp;').replace(/</g, '&lt;').replace(/>/g, '&gt;').replace(/"/g, '&quot;');
      };
      const level = (fraud.risk_level || '').toLowerCase();
      const riskClass = level === 'high' ? 'high' : (level === 'medium' ? 'medium' : 'low');
      const score = fraud.risk_score != null ? Math.round(fraud.risk_score) : '‚Äî';
      const scamType = esc(fraud.scam_type || '‚Äî');
      const summary = (fraud.signals && fraud.signals.gemini && fraud.signals.gemini.summary) ? esc(fraud.signals.gemini.summary) : '';
      const recommendation = (fraud.recommendation) ? esc(fraud.recommendation) : ((fraud.signals && fraud.signals.gemini && fraud.signals.gemini.recommendation) ? esc(fraud.signals.gemini.recommendation) : '');
      const evidence = Array.isArray(fraud.evidence) ? fraud.evidence : [];
      const evidenceList = evidence.map(e => '<li>' + esc(typeof e === 'string' ? e : (e.text || e.reason || JSON.stringify(e))) + '</li>').join('');
      return `<div class="fraud-title">üõ° Fraud / scam</div>
        <div class="fraud-risk ${riskClass}">Risk: ${esc(fraud.risk_level || '‚Äî')} (${score})</div>
        ${scamType !== '‚Äî' ? `<div style="margin-top:2px">Scam: ${scamType}</div>` : ''}
        ${summary ? `<div style="margin-top:4px">${summary}</div>` : ''}
        ${recommendation ? `<div style="margin-top:4px; font-weight:700; color:#1E293B;">üí° Action: ${recommendation}</div>` : ''}
        ${evidenceList ? `<ul class="fraud-evidence">${evidenceList}</ul>` : ''}`;
    }

    // ---- Audio visualization ----
    function startAudioVisualization(mediaStream) {
      try {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        if (audioContext.state === 'suspended') {
          audioContext.resume().catch(() => { });
        }
        const source = audioContext.createMediaStreamSource(mediaStream);
        analyserNode = audioContext.createAnalyser();
        analyserNode.fftSize = 256;
        source.connect(analyserNode);

        drawAudioWaveform();
      } catch (err) {
        console.error('Audio viz failed:', err);
      }
    }

    function drawAudioWaveform() {
      if (!analyserNode) return;

      const bufferLength = analyserNode.frequencyBinCount;
      const dataArray = new Uint8Array(bufferLength);

      function draw() {
        animFrameId = requestAnimationFrame(draw);
        analyserNode.getByteFrequencyData(dataArray);

        const w = audioCanvas.width = audioCanvas.clientWidth;
        const h = audioCanvas.height = audioCanvas.clientHeight;
        audioCtx2d.clearRect(0, 0, w, h);

        const barWidth = (w / bufferLength) * 2;
        let x = 0;

        for (let i = 0; i < bufferLength; i++) {
          const barHeight = (dataArray[i] / 255) * h;
          const hue = 240 + (dataArray[i] / 255) * 60; // blue to purple
          audioCtx2d.fillStyle = `hsla(${hue}, 70%, 60%, 0.8)`;
          audioCtx2d.fillRect(x, h - barHeight, barWidth - 1, barHeight);
          x += barWidth;
        }
      }

      draw();
    }

    // ---- Helpers ----
    const BAND_LABELS = { HIGH: 'High confidence', MEDIUM: 'Medium confidence', LOW: 'Low confidence' };

    function getEmoji(pred) {
      switch (pred) {
        case 'fake': return 'üö®';
        case 'real': return '‚úÖ';
        default: return '‚ùì';
      }
    }

    function addLog(type, message) {
      const entry = document.createElement('div');
      entry.className = `log-entry ${type}`;
      entry.innerHTML = message;
      logContainer.prepend(entry);
      while (logContainer.children.length > 50) {
        logContainer.removeChild(logContainer.lastChild);
      }
    }

    function toggleDetails() {
      const toggle = document.getElementById('detailsToggle');
      const body = document.getElementById('detailsBody');
      toggle.classList.toggle('open');
      body.classList.toggle('open');
    }

    // Render a user-friendly verdict card into a container element
    function renderVerdictCard(container, result, mediaLabel) {
      const v = result.verdict || 'UNCERTAIN';
      const vl = v.toLowerCase();
      const band = BAND_LABELS[result.confidence_band] || 'Checking...';
      const why = result.advice ? result.advice.why : '';
      const steps = result.advice ? result.advice.next_steps || [] : [];
      const emoji = getEmoji(vl);
      const colors = { real: '#22C55E', fake: '#EF4444', uncertain: '#F59E0B' };
      const color = colors[vl] || '#818CF8';

      const showSteps = mediaLabel === 'video' && v === 'UNCERTAIN';
      const stepsHtml = showSteps ? steps.map(s => `<li>${s}</li>`).join('') : '';

      container.innerHTML = `
        <div style="text-align:center; padding:8px 0">
          <div class="vc-icon">${emoji}</div>
          <div class="vc-verdict" style="color:${color}">${v}</div>
          <div class="vc-band" style="color:${color}">${band}</div>
        </div>
        <div class="vc-why">${why}</div>
        ${stepsHtml ? `<ul class="vc-steps">${stepsHtml}</ul>` : ''}
      `;
    }


    // =========================================================================
    // FLOATING WIDGET  (Document PiP ‚Üí popup fallback)
    // Stays visible on top of all other windows / tabs while you browse.
    // =========================================================================

    let widgetWindow = null;   // reference to PiP or popup window

    // CSS injected into both Document PiP and popup
    const WIDGET_CSS = `
      * { margin:0; padding:0; box-sizing:border-box; }
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
        background: #0F172A; color: #fff;
        height: 100vh; display: flex; flex-direction: column; overflow: hidden;
        user-select: none;
      }
      .w-header {
        background: #1E293B; padding: 7px 12px;
        font-size: 10px; color: rgba(255,255,255,0.35);
        text-transform: uppercase; letter-spacing: 1.2px;
        display: flex; align-items: center; justify-content: space-between;
        border-bottom: 1px solid rgba(255,255,255,0.05); flex-shrink: 0;
      }
      .w-header .dot { width: 7px; height: 7px; border-radius: 50%; background: #818CF8; flex-shrink:0; }
      .w-thumb-wrap {
        flex-shrink: 0; overflow: hidden; background: #000;
        border-bottom: 1px solid rgba(255,255,255,0.05); display: none;
      }
      .w-thumb-wrap img { width: 100%; height: auto; display: block; }
      .w-main {
        flex: 1; display: flex; flex-direction: column;
        align-items: center; justify-content: center;
        padding: 12px 16px; gap: 4px; transition: background 0.4s;
        text-align: center;
      }
      .w-verdict { font-size: 26px; font-weight: 800; letter-spacing: 3px; transition: color 0.3s; }
      .w-band { font-size: 11px; font-weight: 600; opacity: 0.75; }
      .w-why { font-size: 10px; color: rgba(255,255,255,0.45); margin-top: 4px; line-height: 1.3; }
      .w-divider { border: none; border-top: 1px solid rgba(255,255,255,0.06); margin: 6px 0; width: 100%; display: none; }
      .w-audio-row { display: none; align-items: center; gap: 6px; font-size: 11px; }
      .w-audio-row .wa-icon { font-size: 14px; }
      .w-audio-row .wa-verdict { font-weight: 700; letter-spacing: 1px; }
      .w-audio-row .wa-band { font-size: 10px; opacity: 0.6; }
    `;

    // HTML injected into widget document
    const WIDGET_HTML = `
      <div class="w-header">
        <span>üõ° Realitic</span>
        <div class="dot" id="wDot"></div>
      </div>
      <div class="w-thumb-wrap" id="wThumbWrap">
        <img id="wThumb" alt="">
      </div>
      <div class="w-main" id="wMain">
        <div class="w-verdict" id="wVerdict" style="color:#818CF8">‚è≥ Waiting</div>
        <div class="w-band" id="wBand" style="color:#818CF8">‚Äî</div>
        <div class="w-why" id="wWhy"></div>
        <hr class="w-divider" id="wAudioDivider">
        <div class="w-audio-row" id="wAudioRow">
          <span class="wa-icon">üéô</span>
          <span class="wa-verdict" id="wAudioVerdict">‚Äî</span>
          <span class="wa-band" id="wAudioBand"></span>
        </div>
      </div>
    `;

    function _setupWidgetDoc(doc) {
      const style = doc.createElement('style');
      style.textContent = WIDGET_CSS;
      doc.head.appendChild(style);
      doc.body.innerHTML = WIDGET_HTML;
    }

    async function toggleWidget() {
      if (widgetWindow && !widgetWindow.closed) {
        widgetWindow.close();
        widgetWindow = null;
        _refreshPipBtn();
        return;
      }

      // ‚îÄ‚îÄ Document Picture-in-Picture (Chrome 116+) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      if ('documentPictureInPicture' in window) {
        try {
          const pip = await window.documentPictureInPicture.requestWindow({
            width: 290, height: 340,
          });
          _setupWidgetDoc(pip.document);
          widgetWindow = pip;
          pip.addEventListener('pagehide', () => { widgetWindow = null; _refreshPipBtn(); });
          _refreshPipBtn();
          return;
        } catch (e) {
          // user dismissed or browser rejected ‚Äî fall through to popup
        }
      }

      // ‚îÄ‚îÄ Popup fallback ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
      const popup = window.open(
        '', 'deepfake-widget',
        'width=290,height=340,toolbar=no,menubar=no,location=no,status=no,resizable=yes'
      );
      if (!popup) {
        addLog('uncertain', '‚ö†Ô∏è Popup blocked ‚Äî allow popups for this site to use the widget.');
        return;
      }
      popup.document.open();
      popup.document.write(`<!DOCTYPE html><html><head><meta charset="UTF-8">
        <title>Deepfake Widget</title>
        <style>${WIDGET_CSS}</style></head><body>${WIDGET_HTML}</body></html>`);
      popup.document.close();
      widgetWindow = popup;
      popup.addEventListener('beforeunload', () => { widgetWindow = null; _refreshPipBtn(); });
      _refreshPipBtn();
    }

    function _refreshPipBtn() {
      const btn = document.getElementById('btnPip');
      if (!btn) return;
      const open = widgetWindow && !widgetWindow.closed;
      btn.textContent = open ? '‚úï Close Widget' : '‚ßâ Pop Out';
      btn.classList.toggle('active', open);
    }

    // Update the floating widget after each scan
    function updateWidget(verdict, pFake, band, time, thumbDataUrl, why) {
      if (!widgetWindow || widgetWindow.closed) return;

      const doc = widgetWindow.document;
      const colors = { REAL: '#22C55E', FAKE: '#EF4444', UNCERTAIN: '#F59E0B' };
      const bgTints = {
        REAL: 'rgba(34,197,94,0.07)',
        FAKE: 'rgba(239,68,68,0.10)',
        UNCERTAIN: 'rgba(245,158,11,0.08)',
      };
      const emojis = { REAL: '‚úÖ', FAKE: 'üö®', UNCERTAIN: '‚ùì' };
      const color = colors[verdict] || '#818CF8';
      const bgTint = bgTints[verdict] || 'transparent';
      const emoji = emojis[verdict] || '‚è≥';
      const bandLabel = BAND_LABELS[band] || '';

      const $ = id => doc.getElementById(id);
      if (!$('wVerdict')) return;

      // Thumbnail
      const thumbWrap = $('wThumbWrap');
      const thumbImg = $('wThumb');
      if (thumbWrap && thumbImg) {
        if (thumbDataUrl) {
          thumbImg.src = thumbDataUrl;
          thumbWrap.style.display = 'block';
        } else {
          thumbWrap.style.display = 'none';
        }
      }

      // Verdict section
      $('wMain').style.background = bgTint;
      $('wVerdict').textContent = emoji + ' ' + verdict;
      $('wVerdict').style.color = color;
      $('wBand').textContent = bandLabel;
      $('wBand').style.color = color;
      const whyEl = $('wWhy');
      if (whyEl) whyEl.textContent = why || '';

      // Pulse the dot
      const dot = $('wDot');
      if (dot) {
        dot.style.background = color;
        dot.style.boxShadow = `0 0 6px ${color}`;
        setTimeout(() => { if (dot) dot.style.boxShadow = 'none'; }, 600);
      }
    }

    // Push audio analysis result into the widget's audio section
    function updateWidgetAudio(result) {
      if (!widgetWindow || widgetWindow.closed) return;
      const doc = widgetWindow.document;
      const $ = id => doc.getElementById(id);
      if (!$('wAudioVerdict')) return;

      const verdict = result.verdict || 'UNCERTAIN';
      const band = result.confidence_band || '';
      const colors = { REAL: '#22C55E', FAKE: '#EF4444', UNCERTAIN: '#F59E0B' };
      const emojis = { REAL: '‚úÖ', FAKE: 'üö®', UNCERTAIN: '‚ùì' };
      const color = colors[verdict] || '#818CF8';
      const bandLabel = BAND_LABELS[band] || '';

      const divider = $('wAudioDivider');
      const row = $('wAudioRow');
      if (divider) divider.style.display = 'block';
      if (row) row.style.display = 'flex';

      $('wAudioVerdict').textContent = emojis[verdict] + ' ' + verdict;
      $('wAudioVerdict').style.color = color;
      $('wAudioBand').textContent = bandLabel;
      $('wAudioBand').style.color = color;
    }

    // Build a thumbnail (data URL) of the current frame with the face box drawn on it.
    // Uses the already-captured `canvas` (frameCanvas) as the source.
    function createFaceThumbnail(faceBox, verdict) {
      if (!canvas.width || !canvas.height) return null;

      const tw = 290, th = Math.round(290 * canvas.height / canvas.width);
      const tc = document.createElement('canvas');
      tc.width = tw; tc.height = th;
      const tx = tc.getContext('2d');

      // Draw the captured frame
      tx.drawImage(canvas, 0, 0, tw, th);

      if (!faceBox) return tc.toDataURL('image/jpeg', 0.8);

      const colors = { REAL: '#22C55E', FAKE: '#EF4444', UNCERTAIN: '#F59E0B' };
      const color = colors[verdict] || '#818CF8';

      // bbox is normalised (0-1) relative to original video ‚Äî map to thumbnail pixels
      const rx = faceBox.x * tw;
      const ry = faceBox.y * th;
      const rw = faceBox.w * tw;
      const rh = faceBox.h * th;

      // Glow rect
      tx.shadowColor = color;
      tx.shadowBlur = 10;
      tx.strokeStyle = color;
      tx.lineWidth = 2;
      tx.strokeRect(rx, ry, rw, rh);
      tx.shadowBlur = 0;

      // Corner L-brackets
      const cs = Math.min(rw, rh) * 0.20;
      tx.lineWidth = 3;
      const corners = [
        [rx, ry, cs, 0, 0, cs],
        [rx + rw, ry, -cs, 0, 0, cs],
        [rx, ry + rh, cs, 0, 0, -cs],
        [rx + rw, ry + rh, -cs, 0, 0, -cs],
      ];
      for (const [x, y, dx1, dy1, dx2, dy2] of corners) {
        tx.beginPath();
        tx.moveTo(x + dx1, y + dy1);
        tx.lineTo(x, y);
        tx.lineTo(x + dx2, y + dy2);
        tx.stroke();
      }

      return tc.toDataURL('image/jpeg', 0.80);
    }

    // =========================================================================
    // TAB TITLE + FAVICON  (always-on, visible in any tab strip)
    // =========================================================================
    const _faviconCanvas = document.createElement('canvas');
    _faviconCanvas.width = _faviconCanvas.height = 32;

    function updateTabTitle(verdict, bandLabel) {
      const e = { REAL: '‚úÖ', FAKE: 'üö®', UNCERTAIN: '‚ùì' }[verdict] || 'üîç';
      document.title = `${e} ${verdict} ‚Äî ${bandLabel || 'Checking'} ‚Äî Realitic`;
    }

    function updateFavicon(verdict) {
      const colors = { REAL: '#22C55E', FAKE: '#EF4444', UNCERTAIN: '#F59E0B' };
      const marks = { REAL: '‚úì', FAKE: '!', UNCERTAIN: '?' };
      const color = colors[verdict] || '#818CF8';
      const mark = marks[verdict] || '‚Ä¶';

      const c = _faviconCanvas;
      const x = c.getContext('2d');
      x.clearRect(0, 0, 32, 32);

      // Circle background
      x.fillStyle = color;
      x.beginPath(); x.arc(16, 16, 15, 0, Math.PI * 2); x.fill();

      // Inner ring
      x.strokeStyle = 'rgba(255,255,255,0.25)';
      x.lineWidth = 1.5;
      x.beginPath(); x.arc(16, 16, 13, 0, Math.PI * 2); x.stroke();

      // Character
      x.fillStyle = '#fff';
      x.font = 'bold 16px sans-serif';
      x.textAlign = 'center';
      x.textBaseline = 'middle';
      x.fillText(mark, 16, 17);

      const link = document.getElementById('pageFavicon');
      if (link) link.href = c.toDataURL('image/png');
    }

    function resetTabTitle() {
      document.title = 'Realitic ‚Äî Live Detection';
      const link = document.getElementById('pageFavicon');
      if (link) link.href = '';
    }
  </script>
</body>

</html>